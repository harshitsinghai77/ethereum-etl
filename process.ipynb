{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import count, avg, window, row_number, sum, hour, from_unixtime, date_format, to_timestamp, cast, col\n",
    "from pyspark.sql import Window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 20:21:55 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.29.63 instead (on interface wlo1)\n",
      "23/01/08 20:21:55 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 20:21:57 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"EthereumETL\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time analytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The moving average of the number of transactions in a block (for a window of 5 blocks)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to make it simpler, we're reading data from a parquet file instead of kafka topic.\n",
    "1. POC for writing to kafka topic is in send-data-to-kafka.py\n",
    "2. POC for reading from kafka topic is in receive-data-on-kafka.py\n",
    "3. Refer to the comments in those files for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 1:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+----------+------------------+\n",
      "|block_number|count|row_number|       rolling_avg|\n",
      "+------------+-----+----------+------------------+\n",
      "|      480002|    2|         1|               2.0|\n",
      "|      480004|    2|         1|               2.0|\n",
      "|      480006|    4|         1|2.6666666666666665|\n",
      "|      480008|    1|         1|              2.25|\n",
      "|      480012|    3|         1|               2.4|\n",
      "|      480025|    2|         1|               2.4|\n",
      "|      480033|    1|         1|               2.2|\n",
      "|      480036|    1|         1|               1.6|\n",
      "|      480038|    1|         1|               1.6|\n",
      "|      480039|    2|         1|               1.4|\n",
      "|      480041|    1|         1|               1.2|\n",
      "|      480043|    1|         1|               1.2|\n",
      "|      480051|    1|         1|               1.2|\n",
      "|      480052|    1|         1|               1.2|\n",
      "|      480071|    2|         1|               1.2|\n",
      "|      480074|    2|         1|               1.4|\n",
      "|      480080|    1|         1|               1.4|\n",
      "|      480081|    2|         1|               1.6|\n",
      "|      480083|    1|         1|               1.6|\n",
      "|      480089|    1|         1|               1.4|\n",
      "+------------+-----+----------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Read data from Kafka\n",
    "df = spark.read.parquet(\"transactions.parquet\")\n",
    "\n",
    "# group by block number and count the number of transactions\n",
    "df = df.groupBy(\"block_number\").count()\n",
    "\n",
    "# window for row_number \n",
    "windowSpec = Window.partitionBy(\"block_number\").orderBy(\"block_number\")\n",
    "df = df.withColumn(\"row_number\", row_number().over(windowSpec))\n",
    "\n",
    "# window for rolling average\n",
    "windowSpec = Window.partitionBy(\"row_number\").orderBy(\"row_number\").rowsBetween(-4, 0)\n",
    "df = df.withColumn(\"rolling_avg\", avg(\"count\").over(windowSpec))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total value of gas every hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----+--------+\n",
      "|      date|hour|sum(gas)|\n",
      "+----------+----+--------+\n",
      "|2015-11-03|   1|10643000|\n",
      "|2015-11-03|   2|52934000|\n",
      "|2015-11-03|   3|36920244|\n",
      "|2015-11-03|   4|12912000|\n",
      "|2015-11-03|   5|21428000|\n",
      "|2015-11-03|   6|19175000|\n",
      "|2015-11-03|   7|22663000|\n",
      "|2015-11-03|   8|18651000|\n",
      "|2015-11-03|   9|21208000|\n",
      "|2015-11-03|  10|20266000|\n",
      "|2015-11-03|  11|47825318|\n",
      "|2015-11-03|  12|21020000|\n",
      "|2015-11-03|  13|24316000|\n",
      "|2015-11-03|  14|37869000|\n",
      "|2015-11-03|  15|38480327|\n",
      "|2015-11-03|  16|34198425|\n",
      "|2015-11-03|  17|35333904|\n",
      "|2015-11-03|  18|37797318|\n",
      "|2015-11-03|  19|37711000|\n",
      "|2015-11-03|  20|23465201|\n",
      "+----------+----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"transactions.parquet\")\n",
    "\n",
    "df = df.withColumn(\"block_timestamp\", from_unixtime(df[\"block_timestamp\"]))\n",
    "\n",
    "# Extract the hour from the block_timestamp column\n",
    "df = df.withColumn(\"date\", date_format(df[\"block_timestamp\"], \"yyyy-MM-dd\"))\n",
    "df = df.withColumn(\"hour\", hour(df[\"block_timestamp\"]))\n",
    "\n",
    "# Group the data by hour and sum the gas column\n",
    "df = df.groupBy(\"date\", \"hour\").sum(\"gas\")\n",
    "\n",
    "df = df.sort(\"date\", \"hour\")\n",
    "df.show(20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running count of number of transfers sent and received by addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/08 20:22:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:14 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/01/08 20:22:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "+--------------------+--------------------+-----+-------------+\n",
      "|        from_address|          to_address|count|running_count|\n",
      "+--------------------+--------------------+-----+-------------+\n",
      "|0x001356974cded07...|0x70b2f497d45795e...|    1|            1|\n",
      "|0x00318d29ea34e09...|0xdae787ec66e65c6...|    8|            9|\n",
      "|0x00320c624958997...|                null|    1|           10|\n",
      "|0x00320c624958997...|0x271f7e47d2f7c75...|    1|           11|\n",
      "|0x0037ce3d4b7f872...|0xdc6a542f9787692...|    3|           14|\n",
      "|0x004238bfbbe2048...|0x32be343b94f8601...|    7|           21|\n",
      "|0x0044027f906716e...|0x382be769de6c51f...|    1|           22|\n",
      "|0x0047a8033cc6d6c...|                null|   33|           55|\n",
      "|0x0047a8033cc6d6c...|0x0d3cab9bccd590a...|    1|           56|\n",
      "|0x0047a8033cc6d6c...|0x1beda6c9842d155...|    1|           57|\n",
      "|0x0047a8033cc6d6c...|0x1ca43369c72702d...|    2|           59|\n",
      "|0x0047a8033cc6d6c...|0x1d11e5eae3112db...|    1|           60|\n",
      "|0x0047a8033cc6d6c...|0x2bcc5943c226464...|    7|           67|\n",
      "|0x0047a8033cc6d6c...|0x36545a1a147d34b...|    1|           68|\n",
      "|0x0047a8033cc6d6c...|0x3eba6adcf37da3f...|    1|           69|\n",
      "|0x0047a8033cc6d6c...|0x41897c121cc5292...|   13|           82|\n",
      "|0x0047a8033cc6d6c...|0x5a8b5f07a9bd059...|    1|           83|\n",
      "|0x0047a8033cc6d6c...|0x6f13e4b1182935d...|    1|           84|\n",
      "|0x0047a8033cc6d6c...|0x80aef2fc7b5eb21...|    1|           85|\n",
      "|0x0047a8033cc6d6c...|0xaa2fc709333c38b...|    7|           92|\n",
      "+--------------------+--------------------+-----+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.parquet(\"transactions.parquet\")\n",
    "\n",
    "# Group the data by 'from_address' and 'to_address', and count the number of occurrences\n",
    "df_grouped = df.groupBy('from_address', 'to_address').count()\n",
    "\n",
    "# Add a column with the running count of transfers\n",
    "windowSpec = Window.orderBy(\"from_address\", \"to_address\")\n",
    "df_grouped = df_grouped.withColumn('running_count', sum('count').over(windowSpec))\n",
    "\n",
    "# Display the resulting DataFrame\n",
    "df_grouped.show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Clickhouse\n",
    "\n",
    "If you are on linux system:\n",
    "```shell\n",
    "make get-clickhouse-docker-image\n",
    "```\n",
    "\n",
    "and then \n",
    "```shell\n",
    "make start-clickhouse-docker-container \n",
    "```\n",
    "\n",
    "This will download the clickhouse docker-image and start the container. \n",
    "\n",
    "If you're not on Linux environment\n",
    "```shell\n",
    "docker pull clickhouse/clickhouse-server\n",
    "```\n",
    "followed by \n",
    "```shell\n",
    "docker run -d -p 18123:8123 -p19000:9000 --name clickhouse-server --ulimit nofile=262144:262144 clickhouse/clickhouse-server\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import clickhouse_connect\n",
    "\n",
    "# Change the following variables to match your ClickHouse setup\n",
    "clickhouse_host = 'localhost'\n",
    "clickhouse_port = 18123\n",
    "\n",
    "clickhouse_client = clickhouse_connect.get_client(host=clickhouse_host, port=clickhouse_port)\n",
    "\n",
    "def get_create_sql_stmt_from_df(df, table_name):\n",
    "    columns = []\n",
    "    for column, dtype in df.dtypes.items():\n",
    "        if dtype == 'int64':\n",
    "            clickhouse_dtype = 'Int64'\n",
    "        elif dtype == 'float64':\n",
    "            clickhouse_dtype = 'Float64'\n",
    "        elif dtype == 'object':\n",
    "            clickhouse_dtype = 'String'\n",
    "        elif dtype == 'bool':\n",
    "            clickhouse_dtype = 'UInt8'  # ClickHouse uses UInt8 to represent boolean values\n",
    "        else:\n",
    "            clickhouse_dtype = '???'  # Unknown dtype\n",
    "        columns.append(f'{column} {clickhouse_dtype}')\n",
    "    columns_str = ', '.join(columns)\n",
    "    create_table_stmt = f'CREATE TABLE {table_name} ({columns_str}) ENGINE = MergeTree order by {df.dtypes.index[0]}'\n",
    "    return create_table_stmt\n",
    "\n",
    "def execute_sql_stmt(sql_stmt):\n",
    "    clickhouse_client.command(sql_stmt)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data for ClickHouse Ad-hoc analysis\n",
    "\n",
    "Create Table in clickhouse using the schema from the dataframe, and insert the dataframe into the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "execute_sql_stmt(\"\"\"\n",
    "    DROP TABLE IF EXISTS token_transfers\n",
    "\"\"\")\n",
    "\n",
    "execute_sql_stmt(\"\"\"\n",
    "    DROP TABLE IF EXISTS contracts\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the token_transfers.csv file into a DataFrame\n",
    "token_transfers_df = pd.read_csv('token_transfers.csv')\n",
    "\n",
    "# Create the table in ClickHouse from the token_transfers DataFrame\n",
    "create_sql = get_create_sql_stmt_from_df(token_transfers_df, 'token_transfers')\n",
    "execute_sql_stmt(create_sql)\n",
    "\n",
    "# Insert the data into ClickHouse\n",
    "clickhouse_client.insert_df('token_transfers', token_transfers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the token_transfers.csv file into a DataFrame\n",
    "contracts_df = pd.read_csv('contracts.csv')\n",
    "\n",
    "# Create the table in ClickHouse from the token_transfers DataFrame\n",
    "create_sql = get_create_sql_stmt_from_df(contracts_df, 'contracts')\n",
    "execute_sql_stmt(create_sql)\n",
    "\n",
    "# Insert the data into ClickHouse\n",
    "clickhouse_client.insert_df('contracts', contracts_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ad-hoc analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many ERC-20 token contracts were found? (token_address gives the address of the ERC-20 contract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Currently there is no erc20 token_address in the token_transfers.csv\n",
    "# Joining the token_transfers table with the contracts table on the token_address column will return all the erc20 token addresses\n",
    "erc20_sql = \"\"\"\n",
    "    SELECT tt.*, c.is_erc20\n",
    "    FROM token_transfers tt\n",
    "    INNER JOIN contracts c ON tt.token_address = c.address\n",
    "    WHERE c.is_erc20 = True\n",
    "\"\"\"\n",
    "\n",
    "df = clickhouse_client.query_df(erc20_sql)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current balance for any token address (difference between value in transfers involving the address in to_address and from_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token_address</th>\n",
       "      <th>balance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0xf4eced2f682ce333f96f2d8966c613ded8fc95dd</td>\n",
       "      <td>89400000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                token_address   balance\n",
       "0  0xf4eced2f682ce333f96f2d8966c613ded8fc95dd  89400000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_address = '0xf4eced2f682ce333f96f2d8966c613ded8fc95dd'\n",
    "\n",
    "current_balance_sql = f\"\"\"\n",
    "    SELECT\n",
    "        token_address,\n",
    "        SUM(CASE WHEN from_address = '{token_address}' THEN -value ELSE value END) as balance\n",
    "    FROM token_transfers\n",
    "    WHERE token_address = '{token_address}'\n",
    "        OR from_address = '{token_address}'\n",
    "        OR to_address = '{token_address}'\n",
    "    GROUP BY token_address\n",
    "\"\"\"\n",
    "\n",
    "clickhouse_client.query_df(current_balance_sql)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Highest transaction in a block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>block_number</th>\n",
       "      <th>highest_transaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>494065</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>492472</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>492475</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>488872</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>487629</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>494937</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>494938</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>488686</td>\n",
       "      <td>100000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>491355</td>\n",
       "      <td>10100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>484795</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>488984</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>487624</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>487623</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>485593</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>488986</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>496002</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>485327</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>485324</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>485588</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>485320</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>488985</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>485591</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>485590</td>\n",
       "      <td>100000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>495956</td>\n",
       "      <td>1000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>483333</td>\n",
       "      <td>50000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>485883</td>\n",
       "      <td>47110000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>483342</td>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>483390</td>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>492574</td>\n",
       "      <td>10000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>483352</td>\n",
       "      <td>5000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>490452</td>\n",
       "      <td>471100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>487615</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>487616</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>487604</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>484863</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>484856</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>494019</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>484851</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>484872</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>487620</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>483920</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>483909</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>484870</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>483974</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>487617</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>491360</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>487610</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>484859</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>494015</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>487608</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>484866</td>\n",
       "      <td>200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>485642</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>485848</td>\n",
       "      <td>100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>485827</td>\n",
       "      <td>94611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>485948</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>483927</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    block_number  highest_transaction\n",
       "0         494065      100000000000000\n",
       "1         492472      100000000000000\n",
       "2         492475      100000000000000\n",
       "3         488872      100000000000000\n",
       "4         487629      100000000000000\n",
       "5         494937      100000000000000\n",
       "6         494938      100000000000000\n",
       "7         488686      100000000000000\n",
       "8         491355       10100000000000\n",
       "9         484795         100000000000\n",
       "10        488984         100000000000\n",
       "11        487624         100000000000\n",
       "12        487623         100000000000\n",
       "13        485593         100000000000\n",
       "14        488986         100000000000\n",
       "15        496002         100000000000\n",
       "16        485327         100000000000\n",
       "17        485324         100000000000\n",
       "18        485588         100000000000\n",
       "19        485320         100000000000\n",
       "20        488985         100000000000\n",
       "21        485591         100000000000\n",
       "22        485590         100000000000\n",
       "23        495956           1000000000\n",
       "24        483333             50000000\n",
       "25        485883             47110000\n",
       "26        483342             10000000\n",
       "27        483390             10000000\n",
       "28        492574             10000000\n",
       "29        483352              5000000\n",
       "30        490452               471100\n",
       "31        487615               200000\n",
       "32        487616               200000\n",
       "33        487604               200000\n",
       "34        484863               200000\n",
       "35        484856               200000\n",
       "36        494019               200000\n",
       "37        484851               200000\n",
       "38        484872               200000\n",
       "39        487620               200000\n",
       "40        483920               200000\n",
       "41        483909               200000\n",
       "42        484870               200000\n",
       "43        483974               200000\n",
       "44        487617               200000\n",
       "45        491360               200000\n",
       "46        487610               200000\n",
       "47        484859               200000\n",
       "48        494015               200000\n",
       "49        487608               200000\n",
       "50        484866               200000\n",
       "51        485642               100000\n",
       "52        485848               100000\n",
       "53        485827                94611\n",
       "54        485948                50000\n",
       "55        483927                50000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_transaction_in_block_sql = \"\"\"\n",
    "    SELECT block_number, MAX(value) as highest_transaction\n",
    "    FROM token_transfers\n",
    "    GROUP BY block_number\n",
    "    ORDER BY highest_transaction DESC\n",
    "\"\"\"\n",
    "\n",
    "clickhouse_client.query_df(highest_transaction_in_block_sql)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "330de7c55cdd6d2551b6c42978edea050162a88da2655c47726eb4c69db9e142"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
